{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0889deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    database=\"beer\",\n",
    "    user=\"postgre\",\n",
    "    password=\"admin\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5933c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create  table\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE BeersAbv ( id integer,\n",
    "                        ibu integer,\n",
    "                        style varchar(100),\n",
    "                        brewery_id integer,\n",
    "                        abv decimal DEFAULT NULL\n",
    "                      );\n",
    "            \"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE BeerOun ( id integer,\n",
    "                       ibu integer,\n",
    "                       name varchar(255),\n",
    "                       brewery_id integer,\n",
    "                       ounces decimal\n",
    "                      );\n",
    "            \"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE Breweries ( id integer,\n",
    "                         name varchar(255),\n",
    "                         city varchar(100),\n",
    "                         state varchar(10)\n",
    "                      );\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee44d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data into table\n",
    "with open('beers_abv.csv', 'r') as file:\n",
    "    data = csv.reader(file)\n",
    "    next(data) \n",
    "    for r in data:\n",
    "        r = [None if x == '' else x for x in r]\n",
    "        cur.execute(\"INSERT INTO beersabv (id, ibu, style, brewery_id, abv) VALUES (%s, %s, %s, %s, %s)\", r)\n",
    "\n",
    "\n",
    "with open('beers_oun.csv', 'r') as file:\n",
    "    data = csv.reader(file)\n",
    "    next(data) \n",
    "    for r in data:\n",
    "        r = [None if x == '' else x for x in r]\n",
    "        cur.execute(\"INSERT INTO BeerOun (id, ibu, name, brewery_id, ounces) VALUES (%s, %s, %s, %s, %s)\", r)\n",
    "\n",
    "\n",
    "with open('breweries.csv', 'r') as file:\n",
    "    data = csv.reader(file)\n",
    "    next(data) \n",
    "    for r in data:\n",
    "        r = [None if x == '' else x for x in r]\n",
    "        cur.execute(\"INSERT INTO Breweries (id, name, city, state) VALUES (%s, %s, %s, %s)\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba3c788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  ibu                           style  brewery_id    abv\n",
      "0  1436  NaN             American Pale Lager         408  0.050\n",
      "1  2265  NaN         American Pale Ale (APA)         177  0.066\n",
      "2  2264  NaN                    American IPA         177  0.071\n",
      "3  2263  NaN  American Double / Imperial IPA         177  0.090\n",
      "4  2262  NaN                    American IPA         177  0.075\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pandas\")\n",
    "\n",
    "# use pandas read_sql() function to fetch the data from PostgreSQL and create a Pandas DataFrame\n",
    "q = \"SELECT * FROM BeersAbv\"\n",
    "dataframe = pd.read_sql(q, con=conn)\n",
    "print(dataframe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6430632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commit the Changes\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b45fcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ibu</th>\n",
       "      <th>style</th>\n",
       "      <th>abv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>American Pale Lager</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>45.0</td>\n",
       "      <td>Belgian IPA</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>NaN</td>\n",
       "      <td>American Amber / Red Ale</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Schwarzbier</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>40.0</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>NaN</td>\n",
       "      <td>American Amber / Red Ale</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2410 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ibu                           style    abv\n",
       "0      NaN             American Pale Lager  0.050\n",
       "1      NaN         American Pale Ale (APA)  0.066\n",
       "2      NaN                    American IPA  0.071\n",
       "3      NaN  American Double / Imperial IPA  0.090\n",
       "4      NaN                    American IPA  0.075\n",
       "...    ...                             ...    ...\n",
       "2405  45.0                     Belgian IPA  0.067\n",
       "2406   NaN        American Amber / Red Ale  0.052\n",
       "2407   NaN                     Schwarzbier  0.055\n",
       "2408  40.0         American Pale Ale (APA)  0.055\n",
       "2409   NaN        American Amber / Red Ale  0.052\n",
       "\n",
       "[2410 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select only the required Columns\n",
    "dataframe = dataframe.drop(columns=['id', 'brewery_id'])\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4dece45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/05 16:23:50 WARN Utils: Your hostname, cis6180 resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/04/05 16:23:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/05 16:23:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 0) / 1]\r",
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+\n",
      "|ibu|               style|  abv|\n",
      "+---+--------------------+-----+\n",
      "|NaN| American Pale Lager| 0.05|\n",
      "|NaN|American Pale Ale...|0.066|\n",
      "|NaN|        American IPA|0.071|\n",
      "|NaN|American Double /...| 0.09|\n",
      "|NaN|        American IPA|0.075|\n",
      "|NaN|       Oatmeal Stout|0.077|\n",
      "|NaN|American Pale Ale...|0.045|\n",
      "|NaN|     American Porter|0.065|\n",
      "|NaN|American Pale Ale...|0.055|\n",
      "|NaN|American Double /...|0.086|\n",
      "+---+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"APP_BEER\") \\\n",
    "    .config(\"spark.executor.instances\", \"10\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# convert the Pandas DataFrame to a Spark DataFrame\n",
    "spark_df = spark.createDataFrame(dataframe)\n",
    "spark_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46ef70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# filter the DataFrame to only include rows with style column equals to 'American IPA' or 'American Pale Ale (APA)'\n",
    "spark_df = spark_df.filter((col('style') == 'American IPA') | (col('style') == 'American Pale Ale (APA)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ffe2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-----+\n",
      "| ibu|               style|  abv|\n",
      "+----+--------------------+-----+\n",
      "|60.0|American Pale Ale...|0.061|\n",
      "|42.0|American Pale Ale...|0.044|\n",
      "|70.0|        American IPA| 0.07|\n",
      "|70.0|        American IPA| 0.07|\n",
      "|70.0|        American IPA| 0.07|\n",
      "|42.0|American Pale Ale...|0.044|\n",
      "|65.0|        American IPA| 0.07|\n",
      "|82.0|        American IPA| 0.07|\n",
      "|45.0|        American IPA| 0.05|\n",
      "|65.0|        American IPA|0.069|\n",
      "+----+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark_df.na.drop(how='any')\n",
    "spark_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db8225c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier, LinearSVC, OneVsRest\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"style\", outputCol=\"label\")\n",
    "spark_df = indexer.fit(spark_df).transform(spark_df)\n",
    "\n",
    "#training and testing sets\n",
    "(training, test) = spark_df.randomSplit([0.6, 0.4])\n",
    "\n",
    "\n",
    "#single vector column\n",
    "featureCols = [\"ibu\", \"abv\"]\n",
    "assembler = VectorAssembler(inputCols=featureCols, outputCol=\"features\")\n",
    "\n",
    "# Create algorithm object for RF and SVM\n",
    "randf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "svmachine = LinearSVC(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "#OneVsRest object \n",
    "ovr_rf = OneVsRest(classifier=randf, labelCol=\"label\")\n",
    "ovr_svm = OneVsRest(classifier=svmachine, labelCol=\"label\")\n",
    "\n",
    "# Define the pipeline \n",
    "pipeline_rf = Pipeline(stages=[assembler, ovr_rf])\n",
    "pipeline_svm = Pipeline(stages=[assembler, ovr_svm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a104ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid \n",
    "paramGrid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(randf.maxDepth, [5, 10]) \\\n",
    "    .addGrid(randf.numTrees, [20, 50]) \\\n",
    "    .build()\n",
    "\n",
    "paramGrid_svm = ParamGridBuilder() \\\n",
    "    .addGrid(svmachine.maxIter, [10, 20]) \\\n",
    "    .addGrid(svmachine.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "392fb56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a CrossValidator object for Random Forest Classifier\n",
    "CrossValidator_rf = CrossValidator(estimator=pipeline_rf, \n",
    "                       estimatorParamMaps=paramGrid_rf,\n",
    "                       evaluator=MulticlassClassificationEvaluator(), \n",
    "                       numFolds=5)\n",
    "\n",
    "CrossValidator_svm = CrossValidator(estimator=pipeline_svm, \n",
    "                        estimatorParamMaps=paramGrid_svm, \n",
    "                        evaluator=MulticlassClassificationEvaluator(), \n",
    "                        numFolds=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b88b166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/05 16:25:55 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/04/05 16:25:55 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the Data\n",
    "model_randf = CrossValidator_rf.fit(training)\n",
    "model_svm = CrossValidator_svm.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12dc5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_randf = model_randf.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c8a0dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_svm = model_svm.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9356978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 80.33707865168539 %\n",
      "Linear SVM Accuracy: 80.33707865168539 %\n",
      "\n",
      "\n",
      "Random Forest Precision: 0.80237778248887\n",
      "Linear SVM Precision: 0.806760144860247\n",
      "\n",
      "\n",
      "Random Forest Recall: 0.803370786516854\n",
      "Linear SVM Recall: 0.8033707865168539\n",
      "\n",
      "\n",
      "Random Forest F1-Score: 0.8028467961945439\n",
      "Linear SVM F1-Score: 0.8048240857229622\n",
      "\n",
      "\n",
      "Random Forest AuROC: 0.764784946236559\n",
      "Linear SVM AuROC: 0.7752389486260455\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# evaluate accuracy\n",
    "randf_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\") \\\n",
    "    .setMetricName(\"accuracy\") \\\n",
    "    .evaluate(predictions_randf)\n",
    "\n",
    "svm_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\") \\\n",
    "    .setMetricName(\"accuracy\") \\\n",
    "    .evaluate(predictions_svm)\n",
    "\n",
    "#Evaluate precision\n",
    "randf_Precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\") \\\n",
    "    .evaluate(predictions_randf)\n",
    "svm_Precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\") \\\n",
    "    .evaluate(predictions_svm)\n",
    "\n",
    "#Evaluate recall\n",
    "randf_Recall= MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\") \\\n",
    "    .evaluate(predictions_randf)\n",
    "svm_Recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\") \\\n",
    "    .evaluate(predictions_svm)\n",
    "\n",
    "#Evaluate f1-score for both classifiers\n",
    "randf_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\") \\\n",
    "    .evaluate(predictions_randf)\n",
    "svm_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\") \\\n",
    "    .evaluate(predictions_svm)\n",
    "\n",
    "# evaluate AuROC for both classifiers\n",
    "randf_auROC = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\") \\\n",
    "    .setMetricName(\"areaUnderROC\") \\\n",
    "    .evaluate(predictions_randf)\n",
    "svm_auROC = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\") \\\n",
    "    .setMetricName(\"areaUnderROC\") \\\n",
    "    .evaluate(predictions_svm)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Random Forest Accuracy: {} %\".format(randf_accuracy*100))\n",
    "print(\"Linear SVM Accuracy: {} %\".format(svm_accuracy*100))\n",
    "print('\\n')\n",
    "\n",
    "print(\"Random Forest Precision: {}\".format(randf_Precision))\n",
    "print(\"Linear SVM Precision: {}\".format(svm_Precision))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"Random Forest Recall: {}\".format(randf_Recall))\n",
    "print(\"Linear SVM Recall: {}\".format(svm_Recall))\n",
    "print('\\n')\n",
    "\n",
    "print(\"Random Forest F1-Score: {}\".format(randf_f1))\n",
    "print(\"Linear SVM F1-Score: {}\".format(svm_f1))\n",
    "print('\\n')\n",
    "\n",
    "print(\"Random Forest AuROC: {}\".format(randf_auROC))\n",
    "print(\"Linear SVM AuROC: {}\".format(svm_auROC))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adbba770",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
