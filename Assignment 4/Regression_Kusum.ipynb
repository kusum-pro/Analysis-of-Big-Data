{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24202edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b6f6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'/home/cis6180/Downloads/bottle.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d98daf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1fafe67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7fbd70de8eb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = client['Database_Bottle']\n",
    "collection = db['Collection_Bottle']\n",
    "collection.insert_many(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81fef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = collection.find({}, {'_id':0, 'Salnty': 1, 'T_degC': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff01da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dFRame = pd.DataFrame(list(entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d4b7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df=pd.DataFrame()\n",
    "pandas_df[['Salnty', 'T_degC']] = dFRame[['Salnty', 'T_degC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2633daa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/06 04:06:57 WARN Utils: Your hostname, cis6180 resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/04/06 04:06:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/06 04:06:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/06 04:06:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Spark session in Regression\")  \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19854b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a9ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pandas DataFrame to Spark DataFrame\n",
    "spark_Dataf = spark.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6e8ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df = spark_Dataf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dcae338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = sp_df.randomSplit([0.75,0.25], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4b08aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import rand\n",
    "\n",
    "# Define the VectorAssembler to create the feature vector\n",
    "Vec_assembler = VectorAssembler(inputCols=[\"Salnty\"], outputCol=\"features\")\n",
    "\n",
    "# Define the RandomForestRegressor and GBTRegressor models\n",
    "Randomf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"T_degC\")\n",
    "Gboost = GBTRegressor(featuresCol=\"features\", labelCol=\"T_degC\")\n",
    "\n",
    "# Define the parameter grids for cross-validation\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(Randomf.numTrees, [5, 10, 20]) \\\n",
    "    .addGrid(Randomf.maxDepth, [2, 5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "gbt_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(Gboost.maxDepth, [2, 5, 10]) \\\n",
    "    .addGrid(Gboost.maxIter, [10, 20, 50]) \\\n",
    "    .build()\n",
    "\n",
    "#Evaluation Metric\n",
    "evalr = RegressionEvaluator(labelCol=\"T_degC\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# Define the cross-validator for RandomForestRegressor\n",
    "rf_cv = CrossValidator(estimator=Randomf, estimatorParamMaps=rf_param_grid, evaluator=evalr, numFolds=5)\n",
    "\n",
    "# Define the cross-validator for GBTRegressor\n",
    "gbt_cv = CrossValidator(estimator=Gboost, estimatorParamMaps=gbt_param_grid, evaluator=evalr, numFolds=5)\n",
    "\n",
    "# Define the pipeline for the RandomForestRegressor\n",
    "rf_pipeline = Pipeline(stages=[Vec_assembler, rf_cv])\n",
    "\n",
    "# Define the pipeline for the GBTRegressor\n",
    "gbt_pipeline = Pipeline(stages=[Vec_assembler, gbt_cv])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c6ea687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred                    \n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/home/cis6180/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-core_2.12-3.3.1.jar) to field java.nio.charset.Charset.name\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Fit the pipelines using the training data\n",
    "rmodel_ = rf_pipeline.fit(train_df)\n",
    "\n",
    "\n",
    "# Evaluate the models on the test data\n",
    "rpredictions = rmodel_.transform(test_df)\n",
    "\n",
    "rf_rmse = evalr.evaluate(rpredictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "868c07eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/06 04:08:15 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/04/06 04:08:15 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gmodel = gbt_pipeline.fit(train_df)\n",
    "\n",
    "gpredictions = gmodel.transform(test_df)\n",
    "\n",
    "gbt_rmse = evalr.evaluate(gpredictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f5b2817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Random Forest Regressor Metrics:\n",
      "Value of RMSE : 2.38589395763419\n",
      "Value of R-squared: 0.6431987287515488\n",
      "Value of MAE: 1.7742396324496303\n",
      "Value of MSE: 5.692489977075337\n",
      "-------------------------------------------------\n",
      "\n",
      "Gradient-Boosted Tree Regressor Metrics:\n",
      "Value of RMSE: 2.387401839864875\n",
      "Value of MAE: 1.7742766736476665\n",
      "Value of R-squared: 0.642747590252885\n",
      "VAlue of MSE: 5.699687544990191\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define the evaluation metrics\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"T_degC\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"T_degC\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"T_degC\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "evaluator_mse = RegressionEvaluator(labelCol=\"T_degC\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "\n",
    "# Calculate the evaluation metrics for both models\n",
    "rf_rmse = evaluator_rmse.evaluate(rpredictions)\n",
    "gbt_rmse = evaluator_rmse.evaluate(gpredictions)\n",
    "\n",
    "rf_mae = evaluator_mae.evaluate(rpredictions)\n",
    "gbt_mae = evaluator_mae.evaluate(gpredictions)\n",
    "\n",
    "rf_r2 = evaluator_r2.evaluate(rpredictions)\n",
    "gbt_r2 = evaluator_r2.evaluate(gpredictions)\n",
    "\n",
    "rf_mse = evaluator_mse.evaluate(rpredictions)\n",
    "gbt_mse = evaluator_mse.evaluate(gpredictions)\n",
    "\n",
    "# Print the evaluation metrics for both models\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"Random Forest Regressor Metrics:\")\n",
    "print(\"Value of RMSE :\", rf_rmse)\n",
    "print(\"Value of R-squared:\", rf_r2)\n",
    "print(\"Value of MAE:\", rf_mae)\n",
    "print(\"Value of MSE:\", rf_mse)\n",
    "\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "print(\"\\nGradient-Boosted Tree Regressor Metrics:\")\n",
    "print(\"Value of RMSE:\", gbt_rmse)\n",
    "print(\"Value of MAE:\", gbt_mae)\n",
    "print(\"Value of R-squared:\", gbt_r2)\n",
    "print(\"VAlue of MSE:\", gbt_mse)\n",
    "print(\"-------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c8008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
